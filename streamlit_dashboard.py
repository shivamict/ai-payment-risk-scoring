#!/usr/bin/env python3
"""
Streamlit Dashboard for AI Payment Risk Scoring System
Run with: streamlit run streamlit_dashboard.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import sys
from pathlib import Path

# Add src directory to path
sys.path.append(str(Path(__file__).parent / "src"))

from src.data_preparation import DataPreparator
from src.model_training import ModelTrainer
from src.scoring import RiskScorer
from src.utils import StreamlitDashboard, ResultsExporter
from src.main import PaymentRiskPipeline
import config

# Configure Streamlit page
st.set_page_config(
    page_title="AIæ”¯æ‰•ã„ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°",
    page_icon="ðŸ’³",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """Main dashboard application."""
    st.title("ðŸ¤– AIæ”¯æ‰•ã„ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.markdown("### ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆé¡§å®¢æ”¯æ‰•ã„ãƒªã‚¹ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")
    
    # Sidebar navigation
    st.sidebar.title("ðŸŽ¯ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
    page = st.sidebar.selectbox(
        "ãƒšãƒ¼ã‚¸é¸æŠž",
        ["ðŸ  ãƒ›ãƒ¼ãƒ ", "ðŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æž", "ðŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´", "ðŸ“ˆ ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°", "ðŸ“‹ çµæžœ"]    )
    
    if page == "ðŸ  ãƒ›ãƒ¼ãƒ ":
        show_home_page()
    elif page == "ðŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æž":
        show_data_analysis_page()
    elif page == "ðŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´":
        show_model_training_page()
    elif page == "ðŸ“ˆ ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°":
        show_risk_scoring_page()
    elif page == "ðŸ“‹ çµæžœ":
        show_results_page()

def show_home_page():
    """Display the home page."""
    st.header("ðŸ  AIæ”¯æ‰•ã„ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ã¸ã‚ˆã†ã“ã")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### ðŸŽ¯ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦
        ã“ã®AIæ­è¼‰ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã‚’ä½¿ç”¨ã—ã¦é¡§å®¢ã®æ”¯æ‰•ã„ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã—ã¾ã™ï¼š
        - **é«˜åº¦ãªMLãƒ¢ãƒ‡ãƒ«**: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ä»˜ãXGBoost
        - **SHAPèª¬æ˜Ž**: è§£é‡ˆå¯èƒ½ãªãƒªã‚¹ã‚¯è¦å› åˆ†æž
        - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°**: å³åº§ã®ãƒªã‚¹ã‚¯è©•ä¾¡
        - **åŒ…æ‹¬çš„åˆ†æž**: å¤šæ¬¡å…ƒãƒªã‚¹ã‚¯åˆ†æž
        """)
    
    with col2:
        st.markdown("""
        ### ðŸ”§ ä¸»ãªæ©Ÿèƒ½
        - **5æ®µéšŽãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: å®Œå…¨ãªã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å‡¦ç†
        - **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–
        - **ãƒªã‚¹ã‚¯åˆ†é¡ž**: é«˜/ä¸­/ä½Žãƒªã‚¹ã‚¯åˆ†é¡ž
        - **ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½**: CSVã€Excelã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        """)
    
    with col3:
        st.markdown("""
        ### ðŸ“Š ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
        - **ãƒªã‚¹ã‚¯è»½æ¸›**: é«˜ãƒªã‚¹ã‚¯é¡§å®¢ã®æ—©æœŸè­˜åˆ¥
        - **æ„æ€æ±ºå®šæ”¯æ´**: ãƒ‡ãƒ¼ã‚¿é§†å‹•åž‹æ”¯æ‰•ã„ãƒãƒªã‚·ãƒ¼
        - **ã‚³ã‚¹ãƒˆå‰Šæ¸›**: æ”¯æ‰•ã„ä¸å±¥è¡Œã®æœ€å°åŒ–
        - **ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹**: é€æ˜Žã§èª¬æ˜Žå¯èƒ½ãªAI
        """)
    
    st.markdown("---")
    
    # Quick start section
    st.header("ðŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ðŸ“ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded_file = st.file_uploader(
            "é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠžã—ã¦ãã ã•ã„",
            type=['xlsx', 'xls'],
            help="Excelå½¢å¼ã®é¡§å®¢æ”¯æ‰•ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file is not None:
            st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼")
            if st.button("ðŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†", type="primary"):
                process_uploaded_data(uploaded_file)
    
    with col2:
        st.subheader("ðŸŽ² ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è©¦ã™")
        st.info("ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½ã‚’æŽ¢ç´¢ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™")
        
        col2a, col2b = st.columns(2)
        with col2a:
            n_customers = st.number_input("é¡§å®¢æ•°", min_value=100, max_value=10000, value=1000)
        with col2b:
            n_transactions = st.number_input("é¡§å®¢ã‚ãŸã‚Šã®å–å¼•æ•°", min_value=1, max_value=20, value=5)
        
        if st.button("ðŸŽ¯ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»åˆ†æž", type="secondary"):
            generate_sample_analysis(n_customers, n_transactions)

def show_data_analysis_page():
    """
    æ—¥æœ¬èªžãƒ‡ãƒ¼ã‚¿åˆ†æžãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    """
    st.header("ðŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æž")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆæ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼‰
    uploaded_file = st.file_uploader("ðŸ“ é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx", "xls"], help="é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã¨æœªæ‰•ã„ãƒ•ãƒ©ã‚°ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«")
    
    customer_data = None
    
    if uploaded_file:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
            customer_data = process_uploaded_data(uploaded_file)
            
    # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if customer_data is None and os.path.exists("outputs/processed_japanese_data.csv"):
        customer_data = pd.read_csv("outputs/processed_japanese_data.csv")
        st.info("ðŸ’¾ ä¿å­˜æ¸ˆã¿ã®æ—¥æœ¬èªžãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™")
    
    if customer_data is not None:
        # ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã‚µãƒžãƒªãƒ¼")
        st.write(f"ðŸ“‹ ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(customer_data)}")
        
        # åˆ—ã‚’è¡¨ç¤º
        st.write("ðŸ“Š åˆ©ç”¨å¯èƒ½ãªåˆ—:")
        st.write(", ".join(customer_data.columns.tolist()))
        
        # ã‚¿ãƒ–ã‚’ä½œæˆ
        tab1, tab2, tab3 = st.tabs(["ðŸ“ˆ åŸºæœ¬åˆ†æž", "ðŸ’° æ”¯æ‰•ã„åˆ†æž", "ðŸ” ãƒªã‚¹ã‚¯æŒ‡æ¨™"])
        
        with tab1:
            # ä¼šè©±æ™‚é–“ã®åˆ†å¸ƒ
            if 'total_conversation_duration' in customer_data.columns:
                st.subheader("ä¼šè©±æ™‚é–“åˆ†å¸ƒ")
                fig_duration = px.histogram(
                    customer_data, 
                    x='total_conversation_duration', 
                    title='ä¼šè©±æ™‚é–“åˆ†å¸ƒ', 
                    nbins=30
                )
                st.plotly_chart(fig_duration, use_container_width=True)
            
            # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ
            if 'customer_sentiment_score' in customer_data.columns:
                st.subheader("é¡§å®¢æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
                fig_sentiment = px.histogram(
                    customer_data, 
                    x='customer_sentiment_score', 
                    title='é¡§å®¢æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ', 
                    nbins=20
                )
                st.plotly_chart(fig_sentiment, use_container_width=True)
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¨€é‡ã¨é¡§å®¢ç™ºè¨€é‡ã®ç›¸é–¢
            if 'agent_total_sentence' in customer_data.columns and 'customer_total_sentence' in customer_data.columns:
                st.subheader("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨é¡§å®¢ã®ç™ºè¨€é‡")
                fig_talk = px.scatter(
                    customer_data, 
                    x='agent_total_sentence', 
                    y='customer_total_sentence',
                    title='ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨é¡§å®¢ã®ç™ºè¨€é‡ã®é–¢ä¿‚',
                    labels={'agent_total_sentence': 'ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¨€æ•°', 'customer_total_sentence': 'é¡§å®¢ç™ºè¨€æ•°'}
                )
                st.plotly_chart(fig_talk, use_container_width=True)
        
        with tab2:
            # æœªæ‰•ã„ãƒ•ãƒ©ã‚°ã®åˆ†å¸ƒ
            if 'æœªæ‰•FLAG' in customer_data.columns:
                st.subheader("æ”¯æ‰•ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ")
                payment_counts = customer_data['æœªæ‰•FLAG'].value_counts().reset_index()
                payment_counts.columns = ['æ”¯æ‰•ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'ä»¶æ•°']
                
                fig_payment = px.pie(
                    payment_counts, 
                    values='ä»¶æ•°', 
                    names='æ”¯æ‰•ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 
                    title='æ”¯æ‰•ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ',
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                st.plotly_chart(fig_payment, use_container_width=True)
            
            # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨æœªæ‰•ã„ã®é–¢ä¿‚
            if 'customer_sentiment_score' in customer_data.columns and 'æœªæ‰•FLAG' in customer_data.columns:
                st.subheader("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨æ”¯æ‰•ã„ã®é–¢ä¿‚")
                fig_sentiment_payment = px.box(
                    customer_data, 
                    x='æœªæ‰•FLAG', 
                    y='customer_sentiment_score',
                    title='æ”¯æ‰•ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ã®é¡§å®¢æ„Ÿæƒ…ã‚¹ã‚³ã‚¢',
                    labels={'æœªæ‰•FLAG': 'æ”¯æ‰•ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'customer_sentiment_score': 'é¡§å®¢æ„Ÿæƒ…ã‚¹ã‚³ã‚¢'}
                )
                st.plotly_chart(fig_sentiment_payment, use_container_width=True)
        
        with tab3:
            # ãƒªã‚¹ã‚¯è¦å› ã®ç›¸é–¢ãƒžãƒˆãƒªãƒƒã‚¯ã‚¹
            st.subheader("ãƒªã‚¹ã‚¯è¦å› ã®ç›¸é–¢é–¢ä¿‚")
            
            # æ•°å€¤åˆ—ã®ã¿ã‚’é¸æŠž
            numeric_cols = customer_data.select_dtypes(include=['float64', 'int64']).columns.tolist()
            
            # ç›¸é–¢ãƒžãƒˆãƒªãƒƒã‚¯ã‚¹ã®è¨ˆç®—ã¨è¡¨ç¤º
            if len(numeric_cols) > 1:
                corr_matrix = customer_data[numeric_cols].corr()
                fig_corr = px.imshow(
                    corr_matrix, 
                    title='ãƒªã‚¹ã‚¯è¦å› ã®ç›¸é–¢ãƒžãƒˆãƒªãƒƒã‚¯ã‚¹',
                    labels=dict(color="ç›¸é–¢ä¿‚æ•°")
                )
                st.plotly_chart(fig_corr, use_container_width=True)
            
            # ãƒªã‚¹ã‚¯äºˆæ¸¬ã«é‡è¦ãªç‰¹å¾´é‡
            st.subheader("é‡è¦ç‰¹å¾´é‡åˆ†æž")
            st.write("æœªæ‰•ã„äºˆæ¸¬ã«æœ€ã‚‚å½±éŸ¿ã™ã‚‹è¦å› :")
            
            if 'æœªæ‰•FLAG' in customer_data.columns and len(numeric_cols) > 1:
                from sklearn.ensemble import RandomForestClassifier
                
                # å¯¾è±¡å¤‰æ•°ã¨èª¬æ˜Žå¤‰æ•°ã®æº–å‚™
                X = customer_data[numeric_cols].drop('æœªæ‰•FLAG', axis=1, errors='ignore')
                if len(X.columns) > 0 and 'æœªæ‰•FLAG' in customer_data.columns:
                    y = customer_data['æœªæ‰•FLAG']
                    
                    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã§ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨ˆç®—
                    try:
                        model = RandomForestClassifier(n_estimators=50, random_state=42)
                        model.fit(X, y)
                        
                        # ç‰¹å¾´é‡é‡è¦åº¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
                        feature_importance = pd.DataFrame({
                            'ç‰¹å¾´é‡': X.columns,
                            'é‡è¦åº¦': model.feature_importances_
                        }).sort_values('é‡è¦åº¦', ascending=False)
                        
                        # é‡è¦åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
                        fig_importance = px.bar(
                            feature_importance.head(10), 
                            x='é‡è¦åº¦', 
                            y='ç‰¹å¾´é‡',
                            title='ãƒˆãƒƒãƒ—10é‡è¦ç‰¹å¾´é‡',
                            orientation='h'
                        )
                        st.plotly_chart(fig_importance, use_container_width=True)
                    except Exception as e:
                        st.error(f"ç‰¹å¾´é‡é‡è¦åº¦åˆ†æžã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                else:
                    st.warning("æ•°å€¤ç‰¹å¾´é‡ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€é‡è¦åº¦åˆ†æžã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
            else:
                st.warning("æœªæ‰•FLAGã¾ãŸã¯æ•°å€¤ç‰¹å¾´é‡ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€é‡è¦åº¦åˆ†æžã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
    else:
        st.info("ðŸ“ åˆ†æžã™ã‚‹ã«ã¯é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

def show_model_training_page():
    """Display the model training page."""
    st.header("ðŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ»è©•ä¾¡")
    
    # Check if data exists
    if 'customer_data' not in st.session_state:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšãƒ‡ãƒ¼ã‚¿åˆ†æžãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    st.subheader("âš™ï¸ è¨“ç·´è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        test_size = st.slider("ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚µã‚¤ã‚º", 0.1, 0.4, 0.2)
        random_state = st.number_input("ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰", 0, 100, 42)
    
    with col2:
        enable_tuning = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’æœ‰åŠ¹åŒ–", value=True)
        cv_folds = st.number_input("äº¤å·®æ¤œè¨¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰æ•°", 2, 10, 5)
    
    if st.button("ðŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´", type="primary"):
        train_model_pipeline(test_size, random_state, enable_tuning, cv_folds)
    
    # Display model results if available
    if 'model_metrics' in st.session_state:
        display_model_results()

def show_risk_scoring_page():
    """Display the risk scoring page."""
    st.header("ðŸ“ˆ ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ»åˆ†æž")
      # Check if model is trained
    if 'trained_model' not in st.session_state:
        st.warning("âš ï¸ è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ãã ã•ã„ã€‚")
        return
    
    if st.button("ðŸŽ¯ ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆ", type="primary"):
        generate_risk_scores()
    
    # Display risk scores if available
    if 'risk_results' in st.session_state:
        display_risk_results()

def show_results_page():
    """Display the results page."""
    st.header("ðŸ“‹ çµæžœãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    # Check if results exist
    if 'risk_results' not in st.session_state:
        st.warning("âš ï¸ çµæžœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        return
    
    risk_results = st.session_state.risk_results
    
    # Results overview
    st.subheader("ðŸ“Š çµæžœæ¦‚è¦")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_customers = len(risk_results)
        st.metric("ç·é¡§å®¢æ•°", total_customers)
    
    with col2:
        high_risk_count = len(risk_results[risk_results['risk_category'] == 'High Risk'])
        st.metric("é«˜ãƒªã‚¹ã‚¯é¡§å®¢æ•°", high_risk_count)
    
    with col3:
        avg_risk_score = risk_results['risk_score'].mean()
        st.metric("å¹³å‡ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢", f"{avg_risk_score:.2f}")
    
    with col4:
        if 'model_metrics' in st.session_state:
            accuracy = st.session_state.model_metrics.get('accuracy', 0)
            st.metric("ãƒ¢ãƒ‡ãƒ«ç²¾åº¦", f"{accuracy:.3f}")
    
    # Risk distribution
    st.subheader("ðŸŽ¯ ãƒªã‚¹ã‚¯åˆ†å¸ƒ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Risk score histogram
        fig_hist = px.histogram(risk_results, x='risk_score', title='ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢åˆ†å¸ƒ', nbins=30)
        st.plotly_chart(fig_hist, use_container_width=True)
    
    with col2:
        # Risk category pie chart
        risk_counts = risk_results['risk_category'].value_counts()
        fig_pie = px.pie(values=risk_counts.values, names=risk_counts.index, 
                        title='ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†å¸ƒ')
        st.plotly_chart(fig_pie, use_container_width=True)
    
    # Export options
    st.subheader("ðŸ’¾ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ðŸ“Š ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (CSV)"):
            csv_data = risk_results.to_csv(index=False)
            st.download_button(
                label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name="risk_scores.csv",
                mime="text/csv"
            )
    
    with col2:
        if st.button("ðŸ“ˆ å¯è¦–åŒ–ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
            st.info("å¯è¦–åŒ–ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã¯ã“ã“ã«å®Ÿè£…ã•ã‚Œã¾ã™")
    
    with col3:
        if st.button("ðŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"):
            st.info("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ã¯ã“ã“ã«å®Ÿè£…ã•ã‚Œã¾ã™")
    
    # Detailed results table
    st.subheader("ðŸ“‹ è©³ç´°çµæžœ")
    
    # Filters
    col1, col2 = st.columns(2)
    
    with col1:
        risk_filter = st.selectbox("ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", 
                                  ['ã™ã¹ã¦'] + list(risk_results['risk_category'].unique()))
    
    with col2:
        score_range = st.slider("ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ç¯„å›²",
                               float(risk_results['risk_score'].min()),
                               float(risk_results['risk_score'].max()),
                               (float(risk_results['risk_score'].min()), 
                                float(risk_results['risk_score'].max())))
    
    # Apply filters
    filtered_results = risk_results.copy()
    
    if risk_filter != 'All':
        filtered_results = filtered_results[filtered_results['risk_category'] == risk_filter]
    
    filtered_results = filtered_results[
        (filtered_results['risk_score'] >= score_range[0]) & 
        (filtered_results['risk_score'] <= score_range[1])
    ]
    
    st.dataframe(filtered_results, use_container_width=True)

def process_uploaded_data(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸæ—¥æœ¬èªžã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã®ãƒã‚§ãƒƒã‚¯
        if uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
            df = pd.read_excel(uploaded_file)
            
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
            from src.data_preparation import DataPreparator
            data_prep = DataPreparator()
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            if 'æœªæ‰•FLAG' not in df.columns or 'ãƒ¬ã‚³ãƒ¼ãƒ‰ç•ªå·' not in df.columns:
                st.error("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªåˆ—ï¼ˆæœªæ‰•FLAGã€ãƒ¬ã‚³ãƒ¼ãƒ‰ç•ªå·ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return None
                
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            st.info("ðŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")
            
            # æ—¥æœ¬èªžãƒ‡ãƒ¼ã‚¿ç”¨ã®ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
            if hasattr(data_prep, 'engineer_features_japanese'):
                processed_df = data_prep.engineer_features_japanese(df)
            else:
                # é€šå¸¸ã®ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                processed_df = data_prep.engineer_features_real_data(df)
            
            st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚{len(processed_df)} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
            
            # å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
            processed_df.to_csv("outputs/processed_japanese_data.csv", index=False)
            
            return processed_df
            
        else:
            st.error("âŒ ã‚¨ãƒ©ãƒ¼: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚Excel (.xlsx, .xls) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return None
            
    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None
def generate_sample_analysis(n_customers, n_transactions):
    """Generate and analyze sample data."""
    try:
        with st.spinner("Generating sample data..."):
            # Initialize data preparator
            data_prep = DataPreparator()
            
            # Generate sample data
            sample_data = data_prep.generate_sample_data(n_customers, n_transactions)
            customer_data = data_prep.aggregate_customer_data(sample_data)
            featured_data = data_prep.engineer_features(customer_data)
            
            # Store in session state
            st.session_state.customer_data = featured_data
            
            st.success(f"âœ… Sample data generated! {len(featured_data)} customers created.")
            st.info("ðŸ‘ˆ Navigate to 'Data Analysis' to explore the generated data.")
            
    except Exception as e:
        st.error(f"âŒ Error generating sample data: {str(e)}")

def train_model_pipeline(test_size, random_state, enable_tuning, cv_folds):
    """Train the ML model."""
    try:
        with st.spinner("Training model..."):
            customer_data = st.session_state.customer_data
            
            # Initialize components
            data_prep = DataPreparator()
            model_trainer = ModelTrainer()
            
            # Prepare ML data
            X, y, feature_names = data_prep.prepare_ml_data(customer_data)
            
            # Train model
            results = model_trainer.train_model(
                X, y, feature_names,
                test_size=test_size,
                random_state=random_state,
                enable_hyperparameter_tuning=enable_tuning,
                cv_folds=cv_folds
            )
            
            # Store results
            st.session_state.model_metrics = results
            st.session_state.trained_model = model_trainer.model
            st.session_state.feature_names = feature_names
            
            st.success("âœ… Model trained successfully!")
            
    except Exception as e:
        st.error(f"âŒ Error training model: {str(e)}")

def display_model_results():
    """Display model training results."""
    metrics = st.session_state.model_metrics
    
    st.subheader("ðŸ“Š Model Performance")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Accuracy", f"{metrics.get('accuracy', 0):.4f}")
    with col2:
        st.metric("Precision", f"{metrics.get('precision', 0):.4f}")
    with col3:
        st.metric("Recall", f"{metrics.get('recall', 0):.4f}")
    with col4:
        st.metric("F1-Score", f"{metrics.get('f1_score', 0):.4f}")
    
    # Feature importance
    if 'feature_importance' in metrics:
        st.subheader("ðŸŽ¯ Feature Importance")
        importance_data = metrics['feature_importance']
        if isinstance(importance_data, dict):
            importance_df = pd.DataFrame(list(importance_data.items()), 
                                       columns=['Feature', 'Importance'])
            importance_df = importance_df.sort_values('Importance', ascending=True)
            
            fig_importance = px.bar(importance_df.tail(15), x='Importance', y='Feature', 
                                  orientation='h', title='Top 15 Feature Importance')
            st.plotly_chart(fig_importance, use_container_width=True)

def generate_risk_scores():
    """Generate risk scores for customers."""
    try:
        with st.spinner("Generating risk scores..."):
            customer_data = st.session_state.customer_data
            model = st.session_state.trained_model
            feature_names = st.session_state.feature_names
            
            # Initialize risk scorer
            risk_scorer = RiskScorer()
            risk_scorer.model = model
            
            # Prepare data
            data_prep = DataPreparator()
            X, y, _ = data_prep.prepare_ml_data(customer_data)
            
            # Generate scores
            risk_results = risk_scorer.score_customers(X, feature_names, customer_data)
            
            # Store results
            st.session_state.risk_results = risk_results
            
            st.success(f"âœ… Risk scores generated for {len(risk_results)} customers!")
            
    except Exception as e:
        st.error(f"âŒ Error generating risk scores: {str(e)}")

def display_risk_results():
    """Display risk scoring results."""
    risk_results = st.session_state.risk_results
    
    st.subheader("ðŸ“ˆ Risk Scoring Results")
    
    # Summary statistics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        avg_score = risk_results['risk_score'].mean()
        st.metric("Average Risk Score", f"{avg_score:.2f}")
    
    with col2:
        high_risk_pct = (risk_results['risk_category'] == 'High Risk').mean() * 100
        st.metric("High Risk %", f"{high_risk_pct:.1f}%")
    
    with col3:
        score_std = risk_results['risk_score'].std()
        st.metric("Score Std Dev", f"{score_std:.2f}")
    
    # Top risk customers
    st.subheader("âš ï¸ Top Risk Customers")
    top_risk = risk_results.nlargest(10, 'risk_score')[['customer_id', 'risk_score', 'risk_category', 'shap_explanation']]
    st.dataframe(top_risk, use_container_width=True)

if __name__ == "__main__":
    main()
